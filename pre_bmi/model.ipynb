{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class BMIDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self,idx\n",
    "                    ):\n",
    "        img_path = self.annotations.iloc[idx, 2]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        bmi_label = float(self.annotations.iloc[idx, 7])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, bmi_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((resize, resize)),  # Chọn kích thước ảnh sau khi augment\n",
    "    transforms.ToTensor(),  # Chuyển ảnh sang tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Chuẩn hóa tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BMIModel,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6, 3) #224x224\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batch1 = nn.BatchNorm2d(6)\n",
    "        self.pool1 = nn.MaxPool2d( 2,2) #111x111\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6 ,10 , 3) # 110 x110\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batch2 = nn.BatchNorm2d(10)\n",
    "        self.pool2 = nn.MaxPool2d( 2,2)# 55x55\n",
    "        \n",
    "        self.l_conv1 = int((224- 3) + 1)\n",
    "        self.l_maxpool1= int((self.l_conv1 - 2)/2 + 1)\n",
    "\n",
    "        self.l_conv2 = int((self.l_maxpool1- 3) + 1)\n",
    "        self.l_maxpool2= int((self.l_conv2 - 2)/2 + 1)        \n",
    "        self.linear = nn.Linear(self.l_maxpool2*self.l_maxpool2*10,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BMIDataset(csv_file ='/home/quanhhh/Documents/pre_bmi/pre_databmi.csv',\n",
    "                     root_dir = '/home/quanhhh/Downloads/DATA_BMI/height_weight/',\n",
    "                     transform = transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations = pd.read_csv('/home/quanhhh/Documents/pre_bmi/pre_databmi.csv')\n",
    "# img_path = annotations.iloc[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up data loader and transformations\n",
    "total_samples = len(dataset)\n",
    "total_samples\n",
    "from torch.utils.data import random_split\n",
    "total_samples = len(dataset)\n",
    "train_size = int(0.7 * total_samples)  # Adjust the split ratio as needed\n",
    "test_size = total_samples - train_size\n",
    "\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 226\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BMIModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = RMSELoss()  # Root Mean Squared Error Loss for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for image, bmi_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(image)\n",
    "\n",
    "            loss = criterion(outputs, bmi_labels.view(-1, 1).float())/len(train_loader)  # Convert to float\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            # Compute the loss (optional, for tracking purposes)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "\n",
    "    # Compute metrics (example: accuracy)\n",
    "    # accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Loss: {loss/len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 24.255720138549805\n",
      "Epoch 2/100, Loss: 17.765771865844727\n",
      "Epoch 3/100, Loss: 11.87490463256836\n",
      "Epoch 4/100, Loss: 8.754712104797363\n",
      "Epoch 5/100, Loss: 9.622421264648438\n",
      "Epoch 6/100, Loss: 10.018963813781738\n",
      "Epoch 7/100, Loss: 8.825141906738281\n",
      "Epoch 8/100, Loss: 7.0407819747924805\n",
      "Epoch 9/100, Loss: 5.773986339569092\n",
      "Epoch 10/100, Loss: 5.429225444793701\n",
      "Epoch 11/100, Loss: 5.363011360168457\n",
      "Epoch 12/100, Loss: 5.188183307647705\n",
      "Epoch 13/100, Loss: 4.8243231773376465\n",
      "Epoch 14/100, Loss: 4.281974792480469\n",
      "Epoch 15/100, Loss: 3.5895016193389893\n",
      "Epoch 16/100, Loss: 2.9358675479888916\n",
      "Epoch 17/100, Loss: 2.6316113471984863\n",
      "Epoch 18/100, Loss: 2.8169877529144287\n",
      "Epoch 19/100, Loss: 2.927126884460449\n",
      "Epoch 20/100, Loss: 2.584408760070801\n",
      "Epoch 21/100, Loss: 1.8272849321365356\n",
      "Epoch 22/100, Loss: 1.5545367002487183\n",
      "Epoch 23/100, Loss: 2.0140390396118164\n",
      "Epoch 24/100, Loss: 1.9215281009674072\n",
      "Epoch 25/100, Loss: 1.2952656745910645\n",
      "Epoch 26/100, Loss: 1.3137915134429932\n",
      "Epoch 27/100, Loss: 1.5978553295135498\n",
      "Epoch 28/100, Loss: 1.3459980487823486\n",
      "Epoch 29/100, Loss: 1.0281933546066284\n",
      "Epoch 30/100, Loss: 1.0841847658157349\n",
      "Epoch 31/100, Loss: 1.1618871688842773\n",
      "Epoch 32/100, Loss: 1.0196268558502197\n",
      "Epoch 33/100, Loss: 0.8168103694915771\n",
      "Epoch 34/100, Loss: 1.0305460691452026\n",
      "Epoch 35/100, Loss: 1.0509120225906372\n",
      "Epoch 36/100, Loss: 1.2248862981796265\n",
      "Epoch 37/100, Loss: 1.240692377090454\n",
      "Epoch 38/100, Loss: 0.9111028909683228\n",
      "Epoch 39/100, Loss: 0.9881188273429871\n",
      "Epoch 40/100, Loss: 1.3957322835922241\n",
      "Epoch 41/100, Loss: 0.8153785467147827\n",
      "Epoch 42/100, Loss: 1.5690487623214722\n",
      "Epoch 43/100, Loss: 0.722331166267395\n",
      "Epoch 44/100, Loss: 1.6047585010528564\n",
      "Epoch 45/100, Loss: 0.7613515853881836\n",
      "Epoch 46/100, Loss: 1.7658520936965942\n",
      "Epoch 47/100, Loss: 0.9272006154060364\n",
      "Epoch 48/100, Loss: 2.2836415767669678\n",
      "Epoch 49/100, Loss: 2.4206130504608154\n",
      "Epoch 50/100, Loss: 0.6695974469184875\n",
      "Epoch 51/100, Loss: 2.2209813594818115\n",
      "Epoch 52/100, Loss: 2.0268728733062744\n",
      "Epoch 53/100, Loss: 1.2468887567520142\n",
      "Epoch 54/100, Loss: 1.6452964544296265\n",
      "Epoch 55/100, Loss: 0.8715772032737732\n",
      "Epoch 56/100, Loss: 1.64979088306427\n",
      "Epoch 57/100, Loss: 1.220229983329773\n",
      "Epoch 58/100, Loss: 1.4839292764663696\n",
      "Epoch 59/100, Loss: 1.4507861137390137\n",
      "Epoch 60/100, Loss: 0.8095083236694336\n",
      "Epoch 61/100, Loss: 0.9075332283973694\n",
      "Epoch 62/100, Loss: 0.9644832611083984\n",
      "Epoch 63/100, Loss: 0.6960015296936035\n",
      "Epoch 64/100, Loss: 1.2917898893356323\n",
      "Epoch 65/100, Loss: 0.9826451539993286\n",
      "Epoch 66/100, Loss: 1.34597909450531\n",
      "Epoch 67/100, Loss: 1.2153452634811401\n",
      "Epoch 68/100, Loss: 0.9294265508651733\n",
      "Epoch 69/100, Loss: 0.9457091689109802\n",
      "Epoch 70/100, Loss: 0.9456784129142761\n",
      "Epoch 71/100, Loss: 0.7014515995979309\n",
      "Epoch 72/100, Loss: 1.3639845848083496\n",
      "Epoch 73/100, Loss: 1.3155078887939453\n",
      "Epoch 74/100, Loss: 0.6524978280067444\n",
      "Epoch 75/100, Loss: 0.6633443236351013\n",
      "Epoch 76/100, Loss: 1.0513869524002075\n",
      "Epoch 77/100, Loss: 0.6481589078903198\n",
      "Epoch 78/100, Loss: 1.481294870376587\n",
      "Epoch 79/100, Loss: 1.5267469882965088\n",
      "Epoch 80/100, Loss: 0.32599931955337524\n",
      "Epoch 81/100, Loss: 0.6071596741676331\n",
      "Epoch 82/100, Loss: 0.831682562828064\n",
      "Epoch 83/100, Loss: 0.375476211309433\n",
      "Epoch 84/100, Loss: 1.561307668685913\n",
      "Epoch 85/100, Loss: 1.5243498086929321\n",
      "Epoch 86/100, Loss: 0.5671259760856628\n",
      "Epoch 87/100, Loss: 0.987551748752594\n",
      "Epoch 88/100, Loss: 0.5295599699020386\n",
      "Epoch 89/100, Loss: 0.7777190804481506\n",
      "Epoch 90/100, Loss: 0.4970746636390686\n",
      "Epoch 91/100, Loss: 0.4561898112297058\n",
      "Epoch 92/100, Loss: 0.510068953037262\n",
      "Epoch 93/100, Loss: 0.7022378444671631\n",
      "Epoch 94/100, Loss: 0.3261203467845917\n",
      "Epoch 95/100, Loss: 0.8686848282814026\n",
      "Epoch 96/100, Loss: 0.5022945404052734\n",
      "Epoch 97/100, Loss: 0.8297243714332581\n",
      "Epoch 98/100, Loss: 0.5130487680435181\n",
      "Epoch 99/100, Loss: 0.7728601694107056\n",
      "Epoch 100/100, Loss: 0.7038830518722534\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, criterion, optimizer, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model,test_loader,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # train_epoch\n",
    "    # test_epoch\n",
    "    # luu model/ tra ve model\n",
    "    # self.best_model = copy.deepcopy(self.model)\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e41069438920b677da0f5961bc4e6feb5d97eaf860276a7a70f8fcc8c0e79bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
